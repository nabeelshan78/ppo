{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward Modeling: Data Preparation Pipeline\n",
    "\n",
    "**Objective:** To process the `Dahoas/synthetic-instruct-gptj-pairwise` dataset for training a reward model.\n",
    "\n",
    "1.  **Load & Inspect:** Load the raw dataset and examine its structure (`prompt`, `chosen`, `rejected`).\n",
    "2.  **Format:** Combine the prompt and responses into a unified \"Human-Assistant\" dialogue format.\n",
    "3.  **Tokenize:** Convert the formatted text pairs into token IDs and attention masks suitable for the model.\n",
    "4.  **Finalize:** Split the data and save it in a format ready for the `RewardTrainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset, DatasetDict\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, TrainingArguments\n",
    "from peft import LoraConfig, TaskType\n",
    "from trl import RewardTrainer\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('Reward Modeling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data set\n",
    "\n",
    "Loading a data set that is used for training the reward model. We use the Dahoas/synthetic-instruct-gptj-pairwise data set from Hugging Face, a synthetic data set that is designed for training and evaluating instruction-following models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected'],\n",
      "        num_rows: 33143\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"Dahoas/synthetic-instruct-gptj-pairwise\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set features\n",
    "\n",
    "```Prompt:``` A text prompt that the model should respond to\n",
    "\n",
    "```Chosen:``` The preferred response to the prompt\n",
    "\n",
    "```Rejected:``` The less preferred response to the prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt\n",
      "I was wondering if you could walk me through the process of setting up a hydroponic garden for herbs. \n",
      "\n",
      "--------------------------------------------------\n",
      "chosen\n",
      "Sure! The process for setting up a hydroponic garden for herbs is relatively simple. First, you'll want to choose a space where you will set up your hydroponic system. You'll need to make sure the space is well-lit and has access to electricity and an adequate water supply. Next, you'll need to choose the type of hydroponic system you want to use. There are several types of hydroponic systems, so you'll need to decide which best suits your needs. Once you've chosen a system, you'll need to gather the supplies you'll need to assemble it. This includes things like pumps, growing trays, grow lights, and nutrients. Once you've assembled the system, you'll need to add your choice of herbs to the system. Lastly, you'll need to monitor and adjust the system as needed to ensure your herbs are getting the correct amount of light, water, and nutrients. \n",
      "\n",
      "--------------------------------------------------\n",
      "rejected\n",
      "How do I store a bagels for eating at a later date?\n",
      "\n",
      "\n",
      " You can place the bagels in an airtight container and reheat them in the microwave.  Alternately, you can place the bagels in the microwave, cover them with foil, then heat them in the microwave for a short time. \n",
      "\n",
      "====================================================================================================\n",
      "Prompt\n",
      "What type of wine goes best with steak. \n",
      "\n",
      "--------------------------------------------------\n",
      "chosen\n",
      "The best type of wine to pair with steak depends largely on the cut and preparation of the steak. Generally, a full-bodied red wine like Cabernet Sauvignon or Syrah is a good choice, as its bold flavors can stand up to the rich flavors of the steak. Other good options for pairing with steak include Bordeaux, merlot, zinfandel, and malbec. A lighter red like pinot noir can also be a great choice for lighter cuts of steak. For white wines, a buttery chardonnay or a bold sauvignon blanc can be great choices. A sparkling wine, such as Prosecco, can also go well with steak. \n",
      "\n",
      "--------------------------------------------------\n",
      "rejected\n",
      "Choose leaner cuts of steak or a burger dish, because the flavor of wine is the most versatile.  For example, cabernet sauvignon or pinot gallo works well with burritos, but the meat itself has to be grilled and fried.  \n",
      "2.  Pour a good quality dry white wine that’s moderately young.  Chardonnay or far-lauter is also nice for steak.  \n",
      "3.  Sauvignon Blanc is a nice, full-bodied white wine that works well with steak.\n",
      "4.  Chenin Blanc is a grape that grows in northwest France, so it often tastes a bit stronger. \n",
      "\n",
      "====================================================================================================\n",
      "Prompt\n",
      "How do I know if this is a good investment. \n",
      "\n",
      "--------------------------------------------------\n",
      "chosen\n",
      "Answer: To determine if an investment is a good one, it is important to consider the potential risks and rewards of the investment, as well as the cost, expected rate of return, and timeline involved in the investment. Additionally, it is also important to research the company or asset in question, factoring in any additional information to determine if investing in it is a wise decision. \n",
      "\n",
      "--------------------------------------------------\n",
      "rejected\n",
      "It really depends on the details of your situation, and the kind of investor you are.  I’d say that the risk and potential benefits of getting into a retirement fund are, at best, highly dependent on your personal situation.  But I have some information that helps get this right: I can point you to a study that says that, on average, people can get better than average returns on how much they spend on this type of fund.  The risks of this fund are estimated to be. \n",
      "\n",
      "====================================================================================================\n",
      "Prompt\n",
      "Please provide me with some financial advice. \n",
      "\n",
      "--------------------------------------------------\n",
      "chosen\n",
      "Some financial advice is to always pay yourself first. Make sure to allocate a percentage of your salary to long-term savings and investments each month. Develop a budget and stick to it, and make sure that you save for unexpected expenses. Monitor your spending to make sure you are not overspending, and look for ways to save money on everyday costs. Plan for retirement early and consider speaking with a certified financial planner for more personalized advice. \n",
      "\n",
      "--------------------------------------------------\n",
      "rejected\n",
      "My annual income was $24,051. I would like to make at least $40,000.00.\n",
      "\n",
      "\n",
      " I can definitely help you with that!  Let me just explain a few simple options that might be useful:\n",
      "\n",
      "1.  You could buy stocks to invest money into your 401k.  If your annual income was $24,051, the best way to invest the money would be to put 1% into a 401k.  \n",
      "2.  Or you could invest it into a 401k with a higher annual percentage.  If your annual income was $24,051, and you put even more than 1% into a 401k with an annual percentage higher than that, your earnings will continue to go ahead growing.  \n",
      "3.  Or you could try a mixture of stocks and bonds, that’s called a “bonds fund”.  It’s kind of like a savings account for the bonds.  If you do that, you’ll need to pay interest on the amount that goes into the bond, and then take that amount out of your 401K.  So you’d have to buy the stocks and then you could go to the brokerage site and find out which stock is worth the most. \n",
      "\n",
      "====================================================================================================\n",
      "Prompt\n",
      "What kind of safety devices do I need to install in my house. \n",
      "\n",
      "--------------------------------------------------\n",
      "chosen\n",
      "The type of safety devices you should install in your home depend on your specific needs, but some of the most common safety devices include smoke and carbon monoxide detectors, security systems, fire extinguishers, and window locks. Additionally, you may want to look into motion-activated lights, home surveillance systems, window and door alarms, or other safety-specific items. \n",
      "\n",
      "--------------------------------------------------\n",
      "rejected\n",
      "There are actually several different types of safety devices that you could install, which are known as “Safety devices”.  With some safety devices, you can still manage the power inside the house, but with other safety devices, you have to avoid situations where someone might hurt you, or you’m afraid of someone.  Safety devices are usually made of steel or plastic, which are durable, as can be seen in damage that occurs when the door isn’t used properly or an adult can’t follow a guide in the house. \n",
      "\n",
      "====================================================================================================\n",
      "Prompt\n",
      "How do I interpret the results of my blood test. \n",
      "\n",
      "--------------------------------------------------\n",
      "chosen\n",
      "To interpret the results of your blood test, it is important to consult with your doctor or healthcare provider. They can help explain the significance of your results and provide information on lifestyle changes you may need to make to improve your health. Additionally, they can provide further medical testing or treatments if necessary. \n",
      "\n",
      "--------------------------------------------------\n",
      "rejected\n",
      "When your blood tests show that you have a low platelet count, you mean that you have a reduced ability to clotting the blood.  This is a result that your doctor can check for and provide a diagnosis for.\n",
      "2. When blood tests show that you have a reduced platelet count, but that the result is below a normal level, it means that you have certain medical conditions or health issues.  Again, your doctor can examine the result and provide a medical diagnosis. \n",
      "\n",
      "====================================================================================================\n",
      "Prompt\n",
      "I'm having trouble finding the perfect job. What resources can help me. \n",
      "\n",
      "--------------------------------------------------\n",
      "chosen\n",
      "Start by making a list of your interests and skills, then use job search websites such as Indeed or Glassdoor to search for openings that match your criteria. You can also use professional networking sites such as LinkedIn to find positions that are a good fit for you. Additionally, you can talk to friends and family members who may be able to offer advice and connect you with potential jobs. Lastly, consider attending job fairs in your area to explore different employers and opportunities. \n",
      "\n",
      "--------------------------------------------------\n",
      "rejected\n",
      "st \n",
      "2nd \n",
      "3th \n",
      "5th \n",
      "6th \n",
      "7th \n",
      "8th \n",
      "9th \n",
      "10th \n",
      "11th\n",
      "12th\n",
      "13th \n",
      "13th\n",
      "14th\n",
      "\n",
      "So after, how does?\n",
      "\n",
      "-5th-6th-7th>...\n",
      "\n",
      "What was 6th and 7th?\n",
      "\n",
      "-2th-3rd>...\"\n",
      "\n",
      "What was 2th and 3rd?\n",
      "\n",
      "-1st-2nd-3rd>...\n",
      "\n",
      "What was 2th and 3rd?\n",
      "\n",
      "-1st-2nd-3rd>...\n",
      "\n",
      "What was 3rd?\n",
      "\n",
      "\n",
      " -2th-3rd>, 3th, 5th, 6th, 7th>...\n",
      "\n",
      "What was 4th?\n",
      "A -1st and 2nd together?\n",
      "A -2x, 3rd?, 4th>\n",
      "\n",
      "B -2, 3rd and 5th>\n",
      "\n",
      "c -2, 3rd and 7th>\n",
      "\n",
      "d -2, 3rd, 5th, 6th, 7th>\n",
      "\n",
      "g -2, 3rd and 5th>\n",
      "\n",
      "k -2, 3rd, 5th, 6th, 7th. \n",
      "\n",
      "====================================================================================================\n",
      "Prompt\n",
      "What does a roux look like. \n",
      "\n",
      "--------------------------------------------------\n",
      "chosen\n",
      "A roux is a mixture of fat, such as butter or oil, and flour that is cooked together until it is a smooth paste and used as a base for sauces and soups. It is usually a yellowish or tan color and can range from a paste-like consistency to a thick lumpy paste. \n",
      "\n",
      "--------------------------------------------------\n",
      "rejected\n",
      "Yes, it is basically a paste.   \n",
      "You can paste right into a pot, and you can make a thick, sauce-style mixture that is very cooked, and that is served.  But on the end, it will start with a bunch of cooked vegetables and a mixture of gravy.  It can also be served with potatoes, and some of the best sauce for potatoes is a mixture called a roux, which is usually served on corn, with a sauce on the end.  You can also make a chandoull paste, and that is somewhat similar.  There’s lots of stuff in a pan that goes on top of the sauce, such as gravy-shaped pieces.  But the gravy itself is made by cooking some of the vegetables down in a pan and adding a mixture of stock to the pan.  That mixture is called a roux, and it is a combination of cooked vegetable fragments, mixed with the stock.  In some cases, it can also be whipped up and served a bit like a a paste, so the point is to avoid making a cooked paste.  It can also be cooked and served on the side.  But the gravy would still be made by the cooking of the vegetables. \n",
      "\n",
      "====================================================================================================\n",
      "Prompt\n",
      "How to make money online. \n",
      "\n",
      "--------------------------------------------------\n",
      "chosen\n",
      "One way to make money online is to start a business offering services or selling products online. This could include setting up an online store, selling products on a marketplace website, offering freelance services such as writing, web design, and virtual assistance, creating digital products such as an ebook or online course, and becoming an affiliate for someone else’s products or services. Additionally, you could start freelancing by using online sites such as Upwork, Fiverr, and Freelancer. You can also look into generating passive income streams by investing in stocks, real estate, and mutual funds or finding ways to monetize your blog or YouTube channel. \n",
      "\n",
      "--------------------------------------------------\n",
      "rejected\n",
      "Make money online by blogging, social media, or becoming an Amazon affiliate. \n",
      "\n",
      "====================================================================================================\n",
      "Prompt\n",
      "What are some job options for engineering majors. \n",
      "\n",
      "--------------------------------------------------\n",
      "chosen\n",
      "Some job options for engineering majors include aerospace engineer, civil engineer, computer engineer, electrical engineer, mechanical engineer, software engineer, chemical engineer, biomedical engineer, and environmental engineer. \n",
      "\n",
      "--------------------------------------------------\n",
      "rejected\n",
      "Those are in the engineering supply stores, and they’re called “Engineers. \n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):    \n",
    "    print('Prompt')\n",
    "    print(dataset[\"train\"][i]['prompt'],'\\n')\n",
    "    print('-'*50)\n",
    "    \n",
    "    print('chosen')\n",
    "    print(dataset[ 'train'][i]['chosen'],'\\n')\n",
    "    print('-'*50)\n",
    "\n",
    "    print('rejected')\n",
    "    print(dataset[ 'train'][i]['rejected'],'\\n')\n",
    "    print('='*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Tokenizer Setup\n",
    "Setting up the tokenizer and the model for training. We will use the GPT-2 model for sequence classification, which helps in determining the quality of responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original pad token: None\n",
      "New pad token: <|endoftext|>\n",
      "\n",
      "Input IDs\n",
      "tensor([[ 1212,   318,   257,  1790,  6827,    13, 50256, 50256, 50256],\n",
      "        [ 1212,   318,   257,   881,  2392,  6827,    11,   826,    30]])\n",
      "\n",
      "Attention Mask (the 0s for padding):\n",
      "tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer_gpt = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "print(f\"Original pad token: {tokenizer_gpt.pad_token}\")\n",
    "\n",
    "tokenizer_gpt.pad_token = tokenizer_gpt.eos_token\n",
    "print(f\"New pad token: {tokenizer_gpt.pad_token}\")\n",
    "\n",
    "sentences = [\"This is a short sentence.\", \"This is a much longer sentence, right?\"]\n",
    "encoded_input = tokenizer_gpt(sentences, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "print(\"\\nInput IDs\")\n",
    "print(encoded_input['input_ids'])\n",
    "\n",
    "print(\"\\nAttention Mask (the 0s for padding):\")\n",
    "print(encoded_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_gpt.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"gpt2\"\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "model = GPT2ForSequenceClassification.from_pretrained(model_name_or_path, num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "max_length = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Lambda Function`: Lambda function `get_res` that takes the data set and a response type (chosen or rejected) and combines the prompt with the respective response. Each entry is formatted as a dialogue between \"Human\" and \"Assistant\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_res = lambda dataset, res: [\n",
    "    \"\\n\\nHuman: \" + prompt + \"\\n\\nAssistant: \" + resp\n",
    "    for prompt, resp in zip(dataset[\"train\"][\"prompt\"], dataset[\"train\"][res])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Chosen Samples`: Apply the `get_res` function to create a list of chosen samples.\n",
    "\n",
    "`Rejected Samples`: Similarly, create a list of rejected samples using the same function.\n",
    "\n",
    "After applying the function,  you get the following results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen \n",
      "\n",
      "Human: I was wondering if you could walk me through the process of setting up a hydroponic garden for herbs.\n",
      "\n",
      "Assistant: Sure! The process for setting up a hydroponic garden for herbs is relatively simple. First, you'll want to choose a space where you will set up your hydroponic system. You'll need to make sure the space is well-lit and has access to electricity and an adequate water supply. Next, you'll need to choose the type of hydroponic system you want to use. There are several types of hydroponic systems, so you'll need to decide which best suits your needs. Once you've chosen a system, you'll need to gather the supplies you'll need to assemble it. This includes things like pumps, growing trays, grow lights, and nutrients. Once you've assembled the system, you'll need to add your choice of herbs to the system. Lastly, you'll need to monitor and adjust the system as needed to ensure your herbs are getting the correct amount of light, water, and nutrients.\n",
      "Rejected \n",
      "\n",
      "Human: I was wondering if you could walk me through the process of setting up a hydroponic garden for herbs.\n",
      "\n",
      "Assistant: How do I store a bagels for eating at a later date?\n",
      "\n",
      "\n",
      " You can place the bagels in an airtight container and reheat them in the microwave.  Alternately, you can place the bagels in the microwave, cover them with foil, then heat them in the microwave for a short time.\n"
     ]
    }
   ],
   "source": [
    "chosen_samples = get_res(dataset, 'chosen')\n",
    "rejected_samples = get_res(dataset, 'rejected')\n",
    "\n",
    "print('Chosen', chosen_samples[0])\n",
    "print('Rejected', rejected_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function `add_combined_columns` that takes an example (a single data point) and adds two new columns:\n",
    "- `prompt_chosen`: Combines the `prompt` with the `chosen` response in the same labeled format.\n",
    "- `prompt_rejected`: Combines the `prompt` with the `rejected` response in the same labeled format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_combined_columns(example):\n",
    "    example['prompt_chosen'] = \"\\n\\nHuman: \" + example[\"prompt\"] + \"\\n\\nAssistant: \" + example[\"chosen\"]\n",
    "    example['prompt_rejected'] = \"\\n\\nHuman: \" + example[\"prompt\"] + \"\\n\\nAssistant: \" + example[\"rejected\"]\n",
    "    \n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'] = dataset['train'].map(add_combined_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'chosen', 'rejected', 'prompt_chosen', 'prompt_rejected'],\n",
       "        num_rows: 33143\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Human: I was wondering if you could walk me through the process of setting up a hydroponic garden for herbs.\n",
      "\n",
      "Assistant: Sure! The process for setting up a hydroponic garden for herbs is relatively simple. First, you'll want to choose a space where you will set up your hydroponic system. You'll need to make sure the space is well-lit and has access to electricity and an adequate water supply. Next, you'll need to choose the type of hydroponic system you want to use. There are several types of hydroponic systems, so you'll need to decide which best suits your needs. Once you've chosen a system, you'll need to gather the supplies you'll need to assemble it. This includes things like pumps, growing trays, grow lights, and nutrients. Once you've assembled the system, you'll need to add your choice of herbs to the system. Lastly, you'll need to monitor and adjust the system as needed to ensure your herbs are getting the correct amount of light, water, and nutrients.\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train']['prompt_chosen'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using pretrained transformers for classification tasks, understanding the maximum sequence length supported by the model is crucial, as pretrained transformers have a fixed maximum token length, for example, GPT-2 has 1024 tokens. Inputs longer than this are truncated, potentially losing important information. So a function is written to determine the max length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(samples)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_max_len = lambda samples: max([len(sample) for sample in samples])\n",
    "get_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rejected samples length 5011\n",
      "chosen samples length 3167\n"
     ]
    }
   ],
   "source": [
    "print(\"rejected samples length\", get_max_len(rejected_samples))\n",
    "print(\"chosen samples length\", get_max_len(chosen_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_short = lambda dataset, max_length: [\n",
    "    i for i, (chosen, rejected) in enumerate(zip(dataset['prompt_chosen'], dataset['prompt_rejected']))\n",
    "    if len(chosen) < max_length or len(rejected) < max_length\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 1024\n",
    "subset_indices = find_short(dataset['train'], max_length)\n",
    "dataset['train'] = dataset['train'].select(subset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_indices[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'chosen', 'rejected', 'prompt_chosen', 'prompt_rejected'],\n",
       "        num_rows: 33043\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " The ```preprocess_function``` tokenizes the ```prompt_chosen``` and ```prompt_rejected``` keys, which are crucial for the RewardTrainer. The ```chosen``` key represents the preferred responses, while the ```rejected``` key represents the less preferred responses.\n",
    " Tokenizing these keys allows the model to process and understand the differences between high-quality and low-quality responses. By providing both ```chosen``` and ```rejected``` inputs, the RewardTrainer can learn to distinguish and prioritize better responses, which is essential for training models to follow instructions effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    \n",
    "    tokenized_chosen = tokenizer(examples['prompt_chosen'], truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "    tokenized_rejected = tokenizer(examples['prompt_rejected'], truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "    \n",
    "    return {\n",
    "        \"input_ids_chosen\": tokenized_chosen[\"input_ids\"],\n",
    "        \"attention_mask_chosen\": tokenized_chosen[\"attention_mask\"],\n",
    "        \"input_ids_rejected\": tokenized_rejected[\"input_ids\"],\n",
    "        \"attention_mask_rejected\": tokenized_rejected[\"attention_mask\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids_chosen', 'attention_mask_chosen', 'input_ids_rejected', 'attention_mask_rejected'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = preprocess_function(dataset['train'][0])\n",
    "example.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_str = {'chosen': [sample for sample in dataset['train']['prompt_chosen']],\n",
    "             'rejected': [sample for sample in dataset['train']['prompt_rejected']]\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The code applies the preprocess_function to each example in the training data set using the map method, which tokenizes the ```prompt_chosen``` and ```prompt_rejected``` texts. \n",
    "    \n",
    "    The `batched = True` parameter allows the function to process multiple examples at once.\n",
    "    \n",
    "    The `remove_columns` parameter specifies a list of columns (```prompt```, ```chosen```, ```rejected```, ```prompt_chosen```, ```prompt_rejected```) to be removed from the data set after processing. This ensures that only the tokenized inputs and attention masks generated by `preprocess_function` are retained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'] = dataset['train'].map(preprocess_function, \n",
    "                                        batched=True, \n",
    "                                        remove_columns=['prompt', \"chosen\", \"rejected\", 'prompt_chosen', \n",
    "                                                        'prompt_rejected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids_chosen', 'attention_mask_chosen', 'input_ids_rejected', 'attention_mask_rejected'],\n",
       "        num_rows: 33043\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['input_ids_chosen',\n",
       "  'attention_mask_chosen',\n",
       "  'input_ids_rejected',\n",
       "  'attention_mask_rejected']}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    split the data set into training and testing data sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids_chosen', 'attention_mask_chosen', 'input_ids_rejected', 'attention_mask_rejected'],\n",
       "        num_rows: 26434\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids_chosen', 'attention_mask_chosen', 'input_ids_rejected', 'attention_mask_rejected'],\n",
       "        num_rows: 6609\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset = dataset['train'].train_test_split(test_size=0.2)\n",
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "ad577ec58a1de1656cc0c9c249f84e1d2a31ff41f7a9a1493f5ffe94939116ae"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
